"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[8847],{7706:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Hi!","href":"/notes/","docId":"hello","unlisted":false},{"type":"link","label":"Agents & Workflows","href":"/notes/Agents & Workflows","docId":"Agents & Workflows","unlisted":false},{"type":"category","label":"Deep learning","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Transformers and attentions","href":"/notes/Deep learning/Transformers and attentions","docId":"Deep learning/Transformers and attentions","unlisted":false}]},{"type":"link","label":"Docusaurus","href":"/notes/Docusaurus","docId":"Docusaurus","unlisted":false},{"type":"link","label":"Evaluations","href":"/notes/Evaluations","docId":"Evaluations","unlisted":false},{"type":"link","label":"Langchain","href":"/notes/Langchain","docId":"Langchain","unlisted":false},{"type":"category","label":"Languages","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"C++","href":"/notes/Languages/C++","docId":"Languages/C++","unlisted":false},{"type":"link","label":"Python","href":"/notes/Languages/Python","docId":"Languages/Python","unlisted":false},{"type":"link","label":"Typescript","href":"/notes/Languages/Typescript","docId":"Languages/Typescript","unlisted":false}],"href":"/notes/category/languages"},{"type":"link","label":"OCR","href":"/notes/OCR","docId":"OCR","unlisted":false},{"type":"category","label":"papers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Why Language Models Hallucinate","href":"/notes/papers/why models hallucinate","docId":"papers/why models hallucinate","unlisted":false}]}]},"docs":{"Agents & Workflows":{"id":"Agents & Workflows","title":"Agents & Workflows","description":"Anthropic Building effective agents","sidebar":"tutorialSidebar"},"Deep learning/Transformers and attentions":{"id":"Deep learning/Transformers and attentions","title":"Transformers and attentions","description":"Theory","sidebar":"tutorialSidebar"},"Docusaurus":{"id":"Docusaurus","title":"Docusaurus","description":"References","sidebar":"tutorialSidebar"},"Evaluations":{"id":"Evaluations","title":"Evaluations","description":"Hallucinations","sidebar":"tutorialSidebar"},"hello":{"id":"hello","title":"Hello","description":"This is a collection of random unstructured / semi-structured notes and thoughts.","sidebar":"tutorialSidebar"},"Langchain":{"id":"Langchain","title":"Langchain","description":"References","sidebar":"tutorialSidebar"},"Languages/C++":{"id":"Languages/C++","title":"C++","description":"References","sidebar":"tutorialSidebar"},"Languages/Python":{"id":"Languages/Python","title":"Python","description":"Async programming","sidebar":"tutorialSidebar"},"Languages/Typescript":{"id":"Languages/Typescript","title":"Typescript","description":"Data Types","sidebar":"tutorialSidebar"},"OCR":{"id":"OCR","title":"OCR","description":"Gemini 2.0 ingesting millions of PDFs","sidebar":"tutorialSidebar"},"papers/why models hallucinate":{"id":"papers/why models hallucinate","title":"Why Language Models Hallucinate","description":"Source//arxiv.org/html/2509.04664v1","sidebar":"tutorialSidebar"}}}}')}}]);