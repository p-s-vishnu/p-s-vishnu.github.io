"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[4117],{582:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/agent_autonomy_levels-8d3d9da62bf1f7741fa7787a60a98743.png"},2991:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/agent_workflow-092069bc9e0b2c3b401a60dac5ed95ad.png"},8378:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Agents & Workflows","title":"Agents & Workflows","description":"Anthropic Building effective agents","source":"@site/notes/Agents & Workflows.md","sourceDirName":".","slug":"/Agents & Workflows","permalink":"/notes/Agents & Workflows","draft":false,"unlisted":false,"editUrl":"https://github.com/p-s-vishnu/p-s-vishnu.github.io/tree/main/notes/Agents & Workflows.md","tags":[{"inline":true,"label":"llm","permalink":"/notes/tags/llm"}],"version":"current","frontMatter":{"title":"Agents & Workflows","tags":["llm"]},"sidebar":"tutorialSidebar","previous":{"title":"Hi!","permalink":"/notes/"},"next":{"title":"Transformers and attentions","permalink":"/notes/Deep learning/Transformers and attentions"}}');var i=t(4848),a=t(8453);const r={title:"Agents & Workflows",tags:["llm"]},o="Theory",l={},c=[{value:"1. Stateful Agent Workflows with LangGraph",id:"1-stateful-agent-workflows-with-langgraph",level:2},{value:"2. Deploying Agents as APIs with FastAPI",id:"2-deploying-agents-as-apis-with-fastapi",level:2},{value:"3. Agent memory with redis",id:"3-agent-memory-with-redis",level:2},{value:"4. Tool &amp; API Integration via Model Context Protocol (MCP)",id:"4-tool--api-integration-via-model-context-protocol-mcp",level:2},{value:"5. A2A (Agent-to-Agent) Communication Protocol",id:"5-a2a-agent-to-agent-communication-protocol",level:2},{value:"Paralant chatbots",id:"paralant-chatbots",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"theory",children:"Theory"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://www.anthropic.com/engineering/building-effective-agents",children:"Anthropic Building effective agents"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Autonomy levels",src:t(582).A+"",width:"1794",height:"1150"})}),"\n",(0,i.jsx)(n.p,{children:"Broad categorisation"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Agent Workflow",src:t(2991).A+"",width:"4572",height:"2047"})}),"\n",(0,i.jsxs)(n.ol,{start:"0",children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Basic Building block: The augmented LLM - LLM enhanced with Retrieval, Memory and Tools."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Predefined paths"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Prompt Chaining"}),"\n",(0,i.jsx)(n.li,{children:"Parallelisation"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"LLM directs control flow in predefined paths - Workflow"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Orchestrator-Worker (Planning pattern)"}),"\n",(0,i.jsx)(n.li,{children:"Evaluator-optimiser (Reflection pattern)"}),"\n",(0,i.jsx)(n.li,{children:"Routing"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"LLM directs its own actions (Open ended problems) - Agent"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h1,{id:"practical",children:"Practical"}),"\n",(0,i.jsxs)(n.h2,{id:"1-stateful-agent-workflows-with-langgraph",children:["1. Stateful Agent Workflows with ",(0,i.jsx)(n.a,{href:"https://github.com/NirDiamant/agents-towards-production/blob/main/tutorials/LangGraph-agent/langgraph_tutorial.ipynb",children:"LangGraph"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"State Management:"})," Maintain persistent state across interactions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flexible Routing:"})," Define complex flows between components"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Persistence:"}),"\xa0Save and resume workflows"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visualisation:"}),"\xa0See and understand your agent's structure"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"General steps:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from langgraph.graph import StateGraph, END\n\n# Memory\nclass State(TypedDict):\n    text: str\n    classification: str\n    entities: List[str]\n    summary: str\n\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema import HumanMessage\n\n# Step 0: Define Tools\ndef classification_node(state: State):\n    \'\'\'Classify the text into one of the categories: News, Blog, Research, or Other\'\'\'\n    prompt = PromptTemplate(\n        input_variables=["text"],\n        template="Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText:{text}\\n\\nCategory:"\n    )\n    message = HumanMessage(content=prompt.format(text=state["text"]))\n    classification = llm.invoke([message]).content.strip()\n    return {"classification": classification}\ndef route_after_classification(state: EnhancedState) -> str:\n    category = state["classification"].lower() # returns: "news", "blog", "research", "other"\n    return category in ["news", "research"]\n\n# Step 1: Create our StateGraph\nworkflow = StateGraph(State)\n\n# Step 2: Define nodes\nworkflow.add_node("classification_node", classification_node)\n\n# Step 3: Define graph\n# Step 3.1: Set the entry point of the graph\nworkflow.set_entry_point("classification_node")\n\n# Step 3.2: Add conditional edges\nworkflow.add_conditional_edges("classification_node", route_after_classification, path_map={\n    True: "entity_extraction",  # TODO: define these tools\n    False: "summarization"      # TODO: define these tools\n})\n\n# Step 3.3: Add static edges\nworkflow.add_edge("classification_node", "entity_extraction")\nworkflow.add_edge("entity_extraction", "summarization")\nworkflow.add_edge("summarization", END)\n\n# Step 3.4: Compile\napp = workflow.compile()\n# Optional: Visualise using mermaid tool\n\n'})}),"\n",(0,i.jsxs)(n.h2,{id:"2-deploying-agents-as-apis-with-fastapi",children:["2. Deploying Agents as APIs with ",(0,i.jsx)(n.a,{href:"https://github.com/NirDiamant/agents-towards-production/blob/main/tutorials/fastapi-agent/fastapi-agent-tutorial.ipynb",children:"FastAPI"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Pytest and ",(0,i.jsx)(n.code,{children:"from fastapi.testclient import TestClient"})," (httpx dependency)."]}),"\n",(0,i.jsxs)(n.li,{children:["Add ",(0,i.jsx)(n.code,{children:"class Config:"})," inside class BaseModel to add example reosne in teh API docs."]}),"\n",(0,i.jsx)(n.li,{children:"Async generation"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import asyncio\n\nclass SimpleAgent:\n    def __init__(self, name="FastAPI Agent"):\n        self.name = name\n\n    async def generate_response_stream(self, query):\n        """Generate a streaming response to a user query"""\n        prefix = f"Agent {self.name} thinking about: \'{query}\'\\n"\n        response = "This is a simulated agent response that streams token by token."\n        # Yield the prefix as a single chunk\n        yield prefix \n        # Stream the response token by token with small delays\n        for token in response.split():\n            await asyncio.sleep(0.1)  # Simulate thinking time\n            yield token + " "\nagent = SimpleAgent()\n\n# Create a streaming endpoint for the agent\n@app.post("/agent/stream")\nasync def stream_agent(request: QueryRequest):\n    """Stream a response from the agent token by token"""\n    \n    async def event_generator():\n        async for token in agent.generate_response_stream(request.query):\n            # Format as a JSON object\n            data = json.dumps({"token": token})\n            yield f"data: {data}\\n\\n"\n\n    return StreamingResponse(\n        event_generator(),\n        media_type="text/event-stream"\n    )\n'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Next steps in the page: advanced agents, fast api background task, async db."}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"3-agent-memory-with-redis",children:["3. ",(0,i.jsx)(n.a,{href:"https://github.com/NirDiamant/agents-towards-production/tree/main/tutorials/agent-memory-with-redis",children:"Agent memory with redis"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Dual-Memory Architecture: Short-term (conversation state) and long-term (persistent knowledge) memory."}),"\n",(0,i.jsx)(n.li,{children:"Semantic Search: RedisVL for semantic memory retrieval with embeddings."}),"\n",(0,i.jsx)(n.li,{children:"Memory Types: Understand differences between Episodic (user experiences) vs Semantic (general knowledge) memory patterns."}),"\n",(0,i.jsx)(n.li,{children:"Production Patterns: Tool-based memory management and conversation summarization"}),"\n",(0,i.jsx)(n.li,{children:"Redis checkpointers for state persistence."}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"4-tool--api-integration-via-model-context-protocol-mcp",children:["4. ",(0,i.jsx)(n.a,{href:"https://github.com/NirDiamant/agents-towards-production/blob/main/tutorials/agent-with-mcp/mcp-tutorial.ipynb",children:"Tool & API Integration via Model Context Protocol (MCP)"})]}),"\n",(0,i.jsxs)(n.p,{children:["Traditional methods of connecting AI models with external resources often involve custom integrations for each ",(0,i.jsx)(n.strong,{children:"data source or tool"}),". This leads to:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integration Complexity"}),": Each new data source requires a unique implementation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scalability Issues"}),": Adding new tools becomes progressively harder"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Maintenance Overhead"}),": Updates to one integration may break others"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"MCP solves these challenges by providing a standardised protocol that enables:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Unified Access"}),": A single interface for multiple data sources and tools"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Plug-and-Play Extensions"}),": Easy addition of new capabilities"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stateful Communication"}),": Real-time, two-way communication between AI and resources"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Discovery"}),": AI can find and use new tools on the fly"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Official MCP Servers:"})," ",(0,i.jsx)(n.a,{href:"https://github.com/modelcontextprotocol/servers/tree/main/src",children:"https://github.com/modelcontextprotocol/servers/tree/main/src"})]}),"\n",(0,i.jsxs)(n.h2,{id:"5-a2a-agent-to-agent-communication-protocol",children:["5. ",(0,i.jsx)(n.a,{href:"https://github.com/NirDiamant/agents-towards-production/blob/main/tutorials/a2a/a2a_tutorial.ipynb",children:"A2A (Agent-to-Agent) Communication Protocol"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"paralant-chatbots",children:"Paralant chatbots"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://www.parlant.io/docs/about",children:"https://www.parlant.io/docs/about"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"References"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://github.com/NirDiamant/agents-towards-production/tree/main?tab=readme-ov-file#-agent-frameworks",children:"NirDiamant Agent framework"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://blog.langchain.com/what-is-a-cognitive-architecture/",children:"https://blog.langchain.com/what-is-a-cognitive-architecture/"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://langchain-ai.github.io/langgraph/",children:"https://langchain-ai.github.io/langgraph/"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://fastapi.tiangolo.com/tutorial/testing/",children:"https://fastapi.tiangolo.com/tutorial/testing/"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(6540);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);